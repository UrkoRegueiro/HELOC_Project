{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5707d313-6d76-47e8-9a02-1ef8c5a9772c",
   "metadata": {},
   "source": [
    "# En este notebook se encuentras las funciones utilizadas a lo largo del proyecto\n",
    "<span style=\"font-size:Large;\">       \n",
    "Se ha instalado el siguiente paquete para cargar las funciones entre notebooks:<br>    \n",
    "<br> \n",
    "    \n",
    "```python\n",
    "! pip install nbimporter\n",
    "```\n",
    "<br>     \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bd16c0-d455-4959-b412-87cf3b9ec0ee",
   "metadata": {},
   "source": [
    "# Paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541be831-0c88-4f5e-a0aa-6358239d7d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\regue\\conda_ENV\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Básicos:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from joblib import dump, load\n",
    "\n",
    "# Procesado de datos:\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model selection:\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV, cross_val_score, cross_val_predict\n",
    "\n",
    "# Modelos de Clasificación:\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Red Neuronal:\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "# Métricas:\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Tiempo:\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85cc6a7-08eb-4b7d-814d-9116c3428d2d",
   "metadata": {},
   "source": [
    "# Funciones para Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606647ff-eb23-4b80-b94b-70fdfb5c4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(variable):\n",
    "    '''\n",
    "    Fución para obtener el límite superior e inferior tras calcular el rango intercuartílico.\n",
    "    '''\n",
    "    Q1 = variable.quantile(q = 0.25)\n",
    "    Q3 = variable.quantile(q = 0.75)\n",
    "\n",
    "    # Rango intercuartil (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Calcular los limites inferior y superior\n",
    "    lim_inf = Q1 - 1.5 * IQR\n",
    "    lim_sup = Q3 + 1.5 * IQR\n",
    "    \n",
    "    return lim_inf, lim_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dddf126c-3849-4f5e-bf75-292f16305830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodo_tukey(df, columna, alfa):\n",
    "    q1 = df[columna].quantile(0.25)\n",
    "    q3 = df[columna].quantile(0.75)\n",
    "    riq = q3 - q1\n",
    "\n",
    "    df = df[df[columna].between(q1 - alfa * riq, q3 + alfa * riq) | (df[columna].isna())]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d003ba-bcdf-469a-961c-9727a3ae3dc1",
   "metadata": {},
   "source": [
    "# Función transformación logarítmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d629c2-8d0b-4af9-9f0b-f8097a17d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logartimo_base2(df, columna):\n",
    "    df[columna] = df[columna].apply(lambda x : np.log2(x+1))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e028a36-09fd-46c6-b429-5259980b044a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Función procesamiento columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c7531f-5c2a-4f6a-aaae-470d682e4670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesamiento_columnas(df):\n",
    "    \n",
    "    df = metodo_tukey(df, 'MSinceOldestTradeOpen', 3)\n",
    "\n",
    "    df = logartimo_base2(df, 'MSinceMostRecentTradeOpen')\n",
    "    df = metodo_tukey(df, 'MSinceMostRecentTradeOpen', 2)\n",
    "\n",
    "    df = metodo_tukey(df, 'AverageMInFile', 3)\n",
    "\n",
    "    df = metodo_tukey(df, 'NumSatisfactoryTrades', 3)\n",
    "\n",
    "    df = logartimo_base2(df, 'NumTrades90Ever_DerogPubRec')\n",
    "\n",
    "    df = logartimo_base2(df, 'PercentTradesNeverDelq')\n",
    "    df = metodo_tukey(df, 'PercentTradesNeverDelq', 4)\n",
    "\n",
    "    df = metodo_tukey(df, 'NumTotalTrades', 3)\n",
    "\n",
    "    df = metodo_tukey(df, 'NumTradesOpeninLast12M', 3)\n",
    "\n",
    "    df = logartimo_base2(df, 'MSinceMostRecentInqexcl7days')\n",
    "\n",
    "    df = logartimo_base2(df, 'NumInqLast6M')\n",
    "    df = metodo_tukey(df, 'NumInqLast6M', 2)\n",
    "\n",
    "    df = metodo_tukey(df, 'NetFractionRevolvingBurden', 3)\n",
    "\n",
    "    df = metodo_tukey(df, 'NetFractionInstallBurden', 3)\n",
    "\n",
    "    df = metodo_tukey(df, 'NumRevolvingTradesWBalance', 4)\n",
    "\n",
    "    df = logartimo_base2(df, 'NumInstallTradesWBalance')\n",
    "    df = metodo_tukey(df, 'NumInstallTradesWBalance', 2)\n",
    "\n",
    "    df = logartimo_base2(df, 'NumBank_NatlTradesWHighUtilization')\n",
    "    df = metodo_tukey(df, 'NumBank_NatlTradesWHighUtilization', 1.5)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f153ce7-a28c-4660-bbc1-d2aa31c987a4",
   "metadata": {},
   "source": [
    "# Fuciones de Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5622122-78bf-4839-be37-aa7283887541",
   "metadata": {},
   "source": [
    "- ## Hold-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5326e702-f996-4b6c-b683-2dd2bee15652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hold_out(modelos, df):\n",
    "    \n",
    "    model_cross_holdout = []\n",
    "\n",
    "    X = df.drop([\"RiskPerformance\"], axis= 1)\n",
    "    y= df[\"RiskPerformance\"]\n",
    "\n",
    "\n",
    "    for modelo in modelos:\n",
    "\n",
    "        accuracy_holdout, precision_holdout, recall_holdout = [], [], []\n",
    "\n",
    "        for i in range(20):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n",
    "            modelo.fit(X_train, y_train)\n",
    "            y_pred = modelo.predict(X_test)\n",
    "\n",
    "            accuracy_holdout.append(accuracy_score(y_test, y_pred))\n",
    "            precision_holdout.append(precision_score(y_test, y_pred, average = \"macro\"))\n",
    "            recall_holdout.append(recall_score(y_test, y_pred, average = \"macro\"))\n",
    "\n",
    "        model_cross_holdout.append([str(modelo).split(\"(\")[0],\n",
    "                                    modelo,\n",
    "                                    np.array(accuracy_holdout).mean(),\n",
    "                                    np.array(precision_holdout).mean(),\n",
    "                                    np.array(recall_holdout).mean()\n",
    "                                   ])\n",
    "\n",
    "    df_cross_holdout = pd.DataFrame(model_cross_holdout, columns= [\"nombre\", \"modelo\" , \"mean_accuracy\", \"mean_precision\", \"mean_recall\"])\n",
    "    df_cross_holdout.to_csv(\"cross_holdout_results.csv\", index= False, sep= \",\")\n",
    "    \n",
    "    return df_cross_holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f82891-4c37-4fe2-a9ca-c5d32d3e6859",
   "metadata": {},
   "source": [
    "## - k-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a3977a-7ff4-42c9-89ec-33fa4c6e9a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(modelos, df, splits= 5):\n",
    "    \n",
    "    model_cross_kfold = []\n",
    "\n",
    "    X = df.drop([\"RiskPerformance\"], axis= 1)\n",
    "    y= df[\"RiskPerformance\"]\n",
    "\n",
    "    kfold = KFold(n_splits = splits)\n",
    "    for modelo in modelos:\n",
    "\n",
    "        y_pred = []\n",
    "\n",
    "        for train_index, test_index in kfold.split(X): \n",
    "\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train = y.iloc[train_index]\n",
    "\n",
    "            modelo.fit(X_train, y_train)\n",
    "            y_pred_1 = modelo.predict(X_test)\n",
    "            y_pred.extend(y_pred_1)\n",
    "\n",
    "        model_cross_kfold.append([str(modelo).split(\"(\")[0],\n",
    "                                  modelo,\n",
    "                                  accuracy_score(y, y_pred),\n",
    "                                  precision_score(y, y_pred, average = \"macro\"),\n",
    "                                  recall_score(y, y_pred, average = \"macro\")\n",
    "                               ])\n",
    "\n",
    "    df_cross_kfold = pd.DataFrame(model_cross_kfold, columns= [\"nombre\", \"modelo\", \"accuracy\", \"precision\", \"recall\"])\n",
    "    df_cross_kfold.to_csv(\"cross_kfold_results.csv\", index= False, sep= \",\")\n",
    "    \n",
    "    return df_cross_kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273b9ef-3ae2-47ae-a05e-5c0e6c8c2787",
   "metadata": {},
   "source": [
    "## - Stratified k-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ccb1a1-4a10-425e-b0dc-c60710877455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_f_fold(modelos, df, splits= 5):    \n",
    "    \n",
    "    model_cross_skfold = []\n",
    "\n",
    "    X = df.drop([\"RiskPerformance\"], axis= 1)\n",
    "    y= df[\"RiskPerformance\"]\n",
    "    \n",
    "    skfold = StratifiedKFold(n_splits = splits)\n",
    "    for modelo in modelos:\n",
    "\n",
    "        y_test_real, y_pred = [], []\n",
    "\n",
    "        for train_index, test_index in skfold.split(X, y):\n",
    "\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            modelo.fit(X_train, y_train)\n",
    "            y_pred_1 = modelo.predict(X_test)\n",
    "            y_pred.extend(y_pred_1)\n",
    "            y_test_real.extend(y_test)\n",
    "\n",
    "        model_cross_skfold.append([str(modelo).split(\"(\")[0],\n",
    "                                   modelo,\n",
    "                                   accuracy_score(y_test_real, y_pred),\n",
    "                                   precision_score(y, y_pred, average = \"macro\"),\n",
    "                                   recall_score(y, y_pred, average = \"macro\")\n",
    "                                    ])\n",
    "\n",
    "    df_cross_skfold = pd.DataFrame(model_cross_skfold, columns= [\"nombre\", \"modelo\" , \"accuracy\", \"precision\", \"recall\"])\n",
    "    df_cross_skfold.to_csv(\"cross_skfold_results.csv\", index= False, sep= \",\")\n",
    "    \n",
    "    return df_cross_skfold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfddfc28-f2d7-498e-bb8f-2bf168798213",
   "metadata": {},
   "source": [
    "# Función para elegir el mejor modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8890f22c-4abc-41a3-b858-78226aa826f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_generator(modelos, df_procesado):\n",
    "\n",
    "    model_results = []\n",
    "\n",
    "    for neighbors in tqdm.tqdm(range(1, 21), desc=\"Progreso\"):\n",
    "        \n",
    "        imputer = KNNImputer(n_neighbors=neighbors)\n",
    "        df_imputed = pd.DataFrame(imputer.fit_transform(df_procesado), columns=df_procesado.columns)\n",
    "        \n",
    "        X = df_imputed.drop([\"RiskPerformance\"], axis=1)\n",
    "        y = df_imputed[\"RiskPerformance\"]\n",
    "\n",
    "        for modelo in modelos:\n",
    "\n",
    "            cv_predictions = cross_val_predict(modelo, X, y, cv=5)\n",
    "\n",
    "            avg_precision = precision_score(y, cv_predictions)\n",
    "            avg_accuracy  = accuracy_score(y, cv_predictions)\n",
    "            avg_recall    = recall_score(y, cv_predictions)\n",
    "\n",
    "            model_results.append([str(modelo).split(\"(\")[0], modelo, avg_accuracy, avg_precision, avg_recall, neighbors, imputer])      \n",
    "\n",
    "    df_resultados_finales = pd.DataFrame(model_results, columns= [\"nombre\", \"modelo\" , \"avg_accuracy\", \"avg_precision\", \"avg_recall\", \"neighbors\", \"imputer\"])\n",
    "\n",
    "    best_imputer = df_resultados_finales.sort_values(by= \"avg_accuracy\", ascending= False).head(1)[\"imputer\"].values[0]\n",
    "    num_vecinos = df_resultados_finales.sort_values(by= \"avg_accuracy\", ascending= False).head(1)[\"neighbors\"].values[0]\n",
    "    \n",
    "    df_final = pd.DataFrame(best_imputer.transform(df_procesado), columns=df_procesado.columns)\n",
    "    df_final.to_csv(f'df_final_{num_vecinos}k.csv', index=False)\n",
    "    print(f\"Se ha guardado el dataframe final como: df_final_{num_vecinos}k.csv \")\n",
    "    \n",
    "    return df_final, df_resultados_finales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f35b07f-4c28-416e-903e-b2696d1c3147",
   "metadata": {},
   "source": [
    "# Función de tunning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a056bd7-f8af-478d-829b-9cec99c88cac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tunning(modelo, parametros, scorer, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    resultados = []\n",
    "\n",
    "    grid_solver = GridSearchCV(estimator  = modelo,\n",
    "                               param_grid = parametros,\n",
    "                               scoring    = scorer,\n",
    "                               cv         = 5,\n",
    "                               refit      = \"accuracy\",\n",
    "                               n_jobs     = 1,\n",
    "                               verbose    = 0\n",
    "                              )\n",
    "\n",
    "    model_result = grid_solver.fit(X_train, y_train)\n",
    "\n",
    "    # Mejor modelo:\n",
    "    best_model = model_result.best_estimator_\n",
    "    params_best_model = best_model.get_params()\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Metricas:\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    resultados.append([str(modelo).split(\"(\")[0], best_model, params_best_model, accuracy, precision, recall])\n",
    "    df_resultados = pd.DataFrame(resultados, columns= [\"Nombre\", \"Modelo\", \"Parametros\",\"Accuracy\", \"Precision\", \"Recall\"])\n",
    "    df_resultados.to_csv(\"resultados_tuning_GBC.csv\", index= \"False\", sep= \",\")\n",
    "    dump(best_model, 'mejor_modelo_gbc.pkl')\n",
    "    \n",
    "    return df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03609bd-e23f-4d6f-aa14-e3ce51655b8e",
   "metadata": {},
   "source": [
    "# Función para Evaluar el Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b5ca33e-d679-4a86-8177-fe2c6a830d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_importance_eval(modelo, X):\n",
    "    \n",
    "    # Calculamos Feature Importance\n",
    "    importances = modelo.feature_importances_\n",
    "\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    columns_plot = []\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "\n",
    "        feature = indices[f]\n",
    "        importancia = importances[indices[f]]\n",
    "        column_name = X.columns[f]\n",
    "\n",
    "        columns_plot.append(column_name)\n",
    "\n",
    "    plt.figure(figsize = (12, 8))\n",
    "\n",
    "    plt.title(\"Feature Importances\")\n",
    "\n",
    "    plt.bar(range(X.shape[1]), importances[indices], color = \"r\", align = \"center\")\n",
    "    plt.xticks(range(X.shape[1]), columns_plot, rotation = 90)\n",
    "    plt.grid()\n",
    "    \n",
    "    return columns_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede908cc-4a5b-446e-9f60-58c88cdd7dec",
   "metadata": {},
   "source": [
    "# Función para Evaluar la Complejidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4ba8d8f-1397-415f-97ed-402616214b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complexity_evaluation(columns_plot, X_train, X_test, y_train, y_test, modelo):\n",
    "\n",
    "    results_columnas = []\n",
    "    \n",
    "    num_cols = len(X_train.columns)\n",
    "\n",
    "    for idx in range(1,(num_cols + 1)):\n",
    "\n",
    "        columnas_menos_importantes = columns_plot[idx :]\n",
    "\n",
    "        X_train_sincol, X_test_sincol = X_train.drop(columnas_menos_importantes, axis = 1), X_test.drop(columnas_menos_importantes, axis = 1)\n",
    "\n",
    "        modelo.fit(X_train_sincol, y_train)\n",
    "\n",
    "        y_pred = modelo.predict(X_test_sincol)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        pre = precision_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "\n",
    "        results_columnas.append([idx, acc, pre, rec])\n",
    "\n",
    "    df_results_columnas = pd.DataFrame(results_columnas, columns= [\"idx_col\", \"Accuracy\", \"Precision\", \"Recall\"])\n",
    "    \n",
    "    return df_results_columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aee450-a489-4795-9924-a8bc8f8ae59f",
   "metadata": {},
   "source": [
    "# Funciones Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77a679ce-8c93-433d-98b9-170ed7f61ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def imputer_knn(data, n_neighbors_range):\n",
    "    imputed_data = {}\n",
    "\n",
    "    for n_neighbors in n_neighbors_range:\n",
    "        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "        imputed_data[n_neighbors] = pd.DataFrame(imputer.fit_transform(data), columns = data.columns)\n",
    "\n",
    "    return imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "918066a8-4a85-4548-ab66-2ad394b3a112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred, y_test, threshold = 0.5):\n",
    "\n",
    "    y_pred_threshold = (np.array(y_pred) > threshold).astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred_threshold)\n",
    "    # True Negatives (TN)\n",
    "    tn = cm[0][0]\n",
    "    # False Positives (FP)\n",
    "    fp = cm[0][1]    \n",
    "    # False Negatives (FN)\n",
    "    fn = cm[1][0]\n",
    "    # True Positives (TP)\n",
    "    tp = cm[1][1]\n",
    "    accuracy  = (tp + tn) / (tp + fn + fp + tn )\n",
    "    precision = tp / (tp + fp)\n",
    "    recall    = tp / (tp + fn)\n",
    "    \n",
    "    return accuracy, precision, recall, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16383b47-6397-4f4c-8225-98dde5eaebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar bucle con diferentes threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bdb7ffc-1d4c-4ad6-9855-7b57f70439dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def FCNN(train, test_size, epochs, early_stopping= True):\n",
    "    \n",
    "    y = train['RiskPerformance']\n",
    "    X = train.drop('RiskPerformance', axis=1)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = test_size, random_state=42, stratify= y)\n",
    "\n",
    "    batch_size = 256\n",
    "    np.random.seed(5)   \n",
    "    metrics = [\"Accuracy\", \"Precision\", \"Recall\"]\n",
    "\n",
    "    #FC1\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_shape= (X_train.shape[1],), units = 150))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #FC2\n",
    "    model.add(Dense(units = 75))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #FC3\n",
    "    model.add(Dense(units = 25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Output layer\n",
    "    model.add(Dense(units= 1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    model.build()\n",
    "    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=metrics)\n",
    "    model.summary()\n",
    "    \n",
    "    if early_stopping:\n",
    "        early_stops = EarlyStopping(patience=10, monitor='Accuracy')\n",
    "        history = model.fit(X_train, y_train, validation_split=test_size, callbacks=[early_stops], batch_size= batch_size, epochs= epochs, verbose=0)\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train, validation_split=test_size, batch_size= batch_size, epochs= epochs, verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return y_pred, y_test, model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a622f298-cc21-424d-8a3a-32e5a5c80064",
   "metadata": {},
   "source": [
    "# Metricas y Visualizaciones Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2d50137-585f-404f-a379-57691a83c5d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_metrics(y_test, y_pred):\n",
    "    \n",
    "    # ROC Curve:\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    \n",
    "    # Precision & Recall:\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "    \n",
    "    # Plots:    \n",
    "    fig, axes = plt.subplots(1, 2, figsize = (12, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # ROC Plot:\n",
    "    axes[0].set_title('Receiver Operating Characteristic')\n",
    "    axes[0].plot(fpr, tpr)\n",
    "    axes[0].plot([0, 1], [0, 1], 'k--')\n",
    "    axes[0].set_xlim([-0.1, 1.1])\n",
    "    axes[0].set_ylim([-0.1, 1.1])\n",
    "    axes[0].set_ylabel('True Positive Rate')\n",
    "    axes[0].set_xlabel('False Positive Rate')\n",
    "\n",
    "    # Precision/Recall Plot:\n",
    "    axes[1].set_title('Precision_Recall')\n",
    "    axes[1].plot(recall, precision)\n",
    "    axes[1].set_xlim([0, 1])\n",
    "    axes[1].set_ylim([0, 1])\n",
    "    axes[1].set_ylabel('Precision')\n",
    "    axes[1].set_xlabel('Recall')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9658044-a4c1-4561-b7ba-55dc68a86632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    accuracy     = history.history[\"Accuracy\"]\n",
    "    loss         = history.history[\"loss\"]\n",
    "\n",
    "    val_accuracy = history.history[\"val_Accuracy\"]\n",
    "    val_loss     = history.history[\"val_loss\"]\n",
    "\n",
    "    epochs = range(1, len(accuracy) + 1)\n",
    "    \n",
    "    # Plots:    \n",
    "    figure, axes = plt.subplots(1, 2, figsize = (12, 6))\n",
    "    axes = axes.flatten() \n",
    "\n",
    "    # Plot Accuracy\n",
    "    axes[0].plot(epochs, accuracy, \"r--\", label=\"Train accuracy\")\n",
    "    axes[0].plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "\n",
    "    axes[0].set_title(\"Training and validation accuracy\")\n",
    "    axes[0].set_ylabel(\"Accuracy\")\n",
    "    axes[0].set_xlabel(\"Epochs\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Plot Loss\n",
    "    axes[1].plot(epochs, loss, \"r--\", label=\"Train loss\")\n",
    "    axes[1].plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "\n",
    "    axes[1].set_title(\"Training and validation loss\")\n",
    "    axes[1].set_ylabel(\"Loss\")\n",
    "    axes[1].set_xlabel(\"Epochs\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
